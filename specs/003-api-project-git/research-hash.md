# リサーチドキュメント: ハッシュベース重複管理実装

**日付**: 2025-09-18
**フェーズ**: 0 (リサーチ)
**スコープ**: ETCデータインポート処理のハッシュベース重複検出・変更管理機能

## 1. ハッシュアルゴリズムの選定

### 決定: xxHash128（重複検出用）+ SHA256（変更検出用）のハイブリッド方式

**根拠**:
- xxHash128は超高速（1-2GB/s）でメモリ効率が良く、重複検出に最適
- SHA256は暗号学的に安全で、データ完全性の保証に適している
- 用途別に使い分けることで性能と安全性を両立

### 検討した代替案:

1. **MD5単独使用**
   - 却下理由: 衝突攻撃が現実的に可能、セキュリティリスク
   - 速度は良好だが、128ビット出力では衝突確率が高い

2. **SHA256単独使用**
   - 却下理由: 重複検出には過剰なセキュリティ、処理速度が2-3倍遅い
   - 変更検出には採用（データ完全性が重要なため）

3. **xxHash64**
   - 却下理由: 64ビットでは月間10万レコード処理で衝突リスクが上昇
   - 128ビット版を採用することで解決

## 2. ハッシュ対象フィールドの決定

### 決定: 2段階アプローチ

**重複検出用（一意性識別）**:
```
- Date（日付）
- Time（時刻）
- ICEntry（入口IC）
- ICExit（出口IC）
- VehicleNo（車両番号）
- CardNo（カード番号）
- TotalAmount（請求金額）
```

**変更検出用（全フィールド）**:
```
上記に加えて:
- Amount（利用金額）
- DiscountAmount（割引金額）
- UsageType（利用区分）
- PaymentMethod（支払方法）
- RouteCode（路線コード）
- Distance（走行距離）
```

**根拠**:
- 重複検出は最小限のフィールドで高速化
- 変更検出は全フィールドで完全性保証
- ETCトランザクションの特性上、日時・場所・車両・金額で一意性確保

## 3. メモリ管理戦略（SQLite不要）

### 決定: ハッシュマップベースのインメモリ管理

**実装方式**:
```go
type HashIndex struct {
    recordHashes  map[string]*models.ETCMeisai  // レコードハッシュ→レコード
    contentHashes map[string]string              // コンテンツハッシュ→レコードハッシュ
    mutex         sync.RWMutex                   // 並行アクセス制御
}
```

**根拠**:
- SQLiteが不要という要件に対応
- ハッシュマップによるO(1)のルックアップ性能
- sync.RWMutexで並行読み込み可能

### メモリ使用量推定:
- 1レコード当たり: 約500バイト（構造体）+ 32バイト（ハッシュ）
- 10万レコード: 約53MB
- 制約の500MB以内に十分収まる

## 4. 差分検出アルゴリズム

### 決定: 3ウェイマージアルゴリズム

**処理フロー**:
1. 新規データのハッシュ計算
2. 既存データのハッシュインデックスと比較
3. 差分を3カテゴリに分類:
   - **追加**: 新規データにのみ存在
   - **更新**: 同一レコードハッシュだがコンテンツハッシュが異なる
   - **削除**: 既存データにのみ存在（オプション）

**実装例**:
```go
type ImportDiff struct {
    Added   []models.ETCMeisai
    Updated []UpdatedRecord
    Deleted []models.ETCMeisai
}

type UpdatedRecord struct {
    Old models.ETCMeisai
    New models.ETCMeisai
}
```

## 5. パフォーマンス最適化

### 決定: バッチ処理とゴルーチン並列化

**実装戦略**:
1. **バッチサイズ**: 1000レコード/バッチ
2. **並列度**: runtime.NumCPU()コア数
3. **チャネルバッファ**: 100レコード

```go
func ProcessInBatches(records []models.ETCMeisai) {
    batchSize := 1000
    workers := runtime.NumCPU()
    jobs := make(chan []models.ETCMeisai, 100)
    results := make(chan *ProcessResult, 100)

    // ワーカープール起動
    for w := 0; w < workers; w++ {
        go hashWorker(jobs, results)
    }

    // バッチ分割と送信
    for i := 0; i < len(records); i += batchSize {
        end := min(i+batchSize, len(records))
        jobs <- records[i:end]
    }
}
```

**根拠**:
- バッチ処理でメモリアロケーション削減
- ゴルーチンでCPU並列化
- チャネルバッファでブロッキング削減

## 6. エラー処理とリカバリー

### 決定: トランザクショナルな更新と監査ログ

**実装方式**:
1. **2フェーズコミット**: 検証フェーズ → 適用フェーズ
2. **監査ログ**: 全ハッシュ操作を記録
3. **部分的成功の許可**: エラーレコードをスキップして継続

```go
type ImportResult struct {
    Success      bool
    ProcessedCount int
    AddedCount    int
    UpdatedCount  int
    ErrorCount    int
    Errors       []ImportError
}

type ImportError struct {
    RecordIndex int
    Error       error
    Record      models.ETCMeisai
}
```

## 7. 実装工数見積もり

| タスク | 工数 | 優先度 |
|--------|------|--------|
| xxHashライブラリ統合 | 2時間 | 高 |
| ハッシュサービス実装 | 4時間 | 高 |
| メモリインデックス実装 | 3時間 | 高 |
| 差分検出アルゴリズム | 4時間 | 中 |
| APIハンドラー実装 | 3時間 | 中 |
| パフォーマンステスト | 2時間 | 低 |
| ドキュメント更新 | 1時間 | 低 |

**合計見積もり**: 19時間（2-3日）

## 8. リスクと対策

### 技術的リスク
1. **メモリ不足**
   - 対策: LRUキャッシュ実装、古いレコードの自動削除

2. **ハッシュ衝突**
   - 対策: 128ビットハッシュ使用、衝突検出ロジック実装

3. **並行アクセス競合**
   - 対策: sync.RWMutex使用、ロック粒度の最適化

### ビジネスリスク
1. **既存データの移行**
   - 対策: 初回インポート時に全レコードのハッシュ計算バッチ実行

2. **パフォーマンス劣化**
   - 対策: ベンチマーク実施、段階的ロールアウト

## 9. ベンチマーク結果（予測）

### 10,000レコード処理
- **ハッシュ計算時間**:
  - xxHash128: 5-10ms
  - SHA256: 100-200ms
- **メモリ使用量**: 約5.3MB
- **総処理時間**: 1-2秒（ハッシュ計算 + インデックス構築）

### 100,000レコード処理
- **ハッシュ計算時間**:
  - xxHash128: 50-100ms
  - SHA256: 1-2秒
- **メモリ使用量**: 約53MB
- **総処理時間**: 5-10秒

## 10. 次のステップ

1. **フェーズ1開始**: データモデル設計
2. **依存ライブラリ追加**: `github.com/cespare/xxhash/v2`
3. **プロトタイプ実装**: 基本的なハッシュ計算機能
4. **ベンチマーク実施**: 実データでのパフォーマンス検証

---

## 結論

ハッシュベース重複管理の実装により、以下の利点が期待できる：

1. **高速な重複検出**: xxHash128により1万レコードを10ms以内で処理
2. **確実な変更追跡**: SHA256により完全なデータ整合性を保証
3. **メモリ効率**: SQLite不要で53MB程度のメモリ使用
4. **スケーラビリティ**: 月間10万レコードを問題なく処理
5. **保守性**: 明確な差分管理により監査証跡を確保

この設計により、ETCデータの重複を99.9%以上の精度で検出し、変更を確実に追跡できるシステムが構築可能。